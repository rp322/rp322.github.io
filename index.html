<!DOCTYPE HTML>
<html xml:lang="en" lang="en">
<head>
  <title>CSE442 | Final Project</title>
  <style media="all">
* { padding: 0; margin: 0; }
 body {
  margin: 0 auto 0 auto;
  padding: 0;
  max-width: 1200px;
  font-family: "Avenir", "Avenir Next", Helvetica Neue, Arial;
  font-size: 0.95em;
}
 a, a:visited { text-decoration: none; color: #7533f4; }
a:hover { text-decoration: underline; color: #f4b014; }
 h1, h2, h3, h4, h5 {
  color: #492a7c;
  background-color: inherit;
  font-weight: normal;
  padding: 0 0 5px 0;
  margin: 15px 0 0 0;
  border: none;
  clear: right;
}
h1 { font-size: 24pt; margin:  5px 0 10px 0; line-height: 28px; }
h2 { font-size: 14pt; margin: 30px 0 15px 0; letter-spacing: 0.01em; border-bottom: 1px solid #ccc;  line-height: 20px;}
h3 { font-size: 13pt; }
h4 { font-size: 12pt; }
h5 { font-size: 11pt; }
p { margin: 0 0 10px 0; }
 .content {
  margin: 0;
  padding: 15px 20px;
  background-color: #ffffff;
}
 .title, .title h1, .title a {
  color: #492a7c;
  font-size: 24pt;
  margin-bottom: 20px;
  margin-top: 5px;
}
 .footer {
  border-top: 1px solid #ccc;
  margin-top: 30px;
  padding-top: 4px;
  text-align: right;
  font-size: 12px;
}
.footer a {
  color: #21346B;
}
.footer a:hover {
  color: #ce3333;
}
  </style>
</head>
<body>
<div class="content">
   <section class="title">
    <a href="/">Exploring Increasing Diversity in Dropout Models</a>
  </section>

   <section>
    <p>
      <strong>Team Members</strong>: Preston Lee, Ryan Park
    </p>
  </section>

  <iframe width="100%" height="766" frameborder="0"
  src="https://observablehq.com/embed/@jakej217/final-project?cell=viewof+demographics&cell=nycMap&cell=viewof+resetButton"></iframe>

  <section>
    <h3>Overview</h3>
    <p>In machine learning, ensemble methods are techniques that are applied to algorithms that can provide more meaningful data points or even more accurate results. For example, algorithms such as logistic regression and na√Øve bayes may be used to predict a certain outcome, but we could potentially combine these algorithms together as some sort of aggregation. Or, we could train an algorithm on subsets of data and combine the results together. For the purpose of this project, we wanted to take a look into the dropout technique. Similar to the methods just mentioned, dropout is an ensemble technique to regularize neural networks. As there has been less research that has been done on the effect of model diversity within dropout, we wanted to do more research and experimentation on this for our final project. In our project, we will attempt to both explore the benefits/disadvantages of output diversity on a neural network outputs as well as find a scheme to enforce dropout diversity for better regularization in neural networks. We will conduct experiments on MNIST and CIFAR10 to compare diverse dropout vs. vanilla dropout.</p>
  </section>

  <section>
    <h3>Datasets</h3>
    <p>Our data set consist of MNIST and CIFAR10. MNIST is a database consisting of 60,000 training images and 10,000 testing images of hand written digits from 0-9. More information about this can be found on its wiki page: https://en.wikipedia.org/wiki/MNIST_database Cifar-10 is a database consisting 60,000 32x32 images of 10 different classes including objects such as airplanes, cars, birds, etc. More information about this dataset can be found on its wiki page: https://en.wikipedia.org/wiki/CIFAR-10</p>
  </section>

  <section>
    <h3>Previous Work</h3>
    <p>
      Our work is motivated by the following article: https://arxiv.org/abs/1908.11091, which is a research paper aimed at the applications of ensemble learning and digging deep into the math behind an increase in ensemble accuracy when prediction errors are more uniformly distributed. We also utilized pytorch and its neural network and adversarial testing libraries to help us dive into our project.</p>
  </section>

  <section>
    <h3>Demo Video</h3>
    <p>https://www.youtube.com/watch?v=wHgVXxTLMRA</p>
  </section>

  <section>
    <h3>Our Approach</h3>
    <p>
      - Population was mostly concentrated in the center of the visualization where most of the subway and bike share stations were located.
     
      - Age tended to be higher on the outskirts of the city, with a few exceptions in the center.
      - 6, 7, and 8 Avenue Express all had highest concentration of bike and subway usages, as they run straight through Manhattan.</p>
  </section>
  
  <section>
    <h3>Results</h3>
    <img src="https://github.com/rp322/rp322.github.io/blob/main/images/AdversarialTestingCIFAR10.png">
    <p>
      <img src=https://github.com/rp322/rp322.github.io/blob/main/images/AdversarialTestingCIFAR10.png">
</p>
  </section>
  
  <section>
    <h3>Observations</h3>
    <p>
      - Population was mostly concentrated in the center of the visualization where most of the subway and bike share stations were located.
     
      - Age tended to be higher on the outskirts of the city, with a few exceptions in the center.
      - 6, 7, and 8 Avenue Express all had highest concentration of bike and subway usages, as they run straight through Manhattan.</p>
  </section>

  <div class="footer">
    <a href="https://courses.cs.washington.edu/courses/cse442/20au/">CSE 442 Data Visualization</a>
    <a href="http://www.washington.edu">University of Washington</a>
  </div>
 </div>
</body>
</html> 
